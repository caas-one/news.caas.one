## 2018年7月9日，星期一

# 基于IPVS的集群负载均衡深入研究 

**作者：杜军（华为）、谢海斌（华为）、魏亮（华为）**              

**编者注：这篇文章是****有关Kubernetes 1.11新增功能的**[**一系列深入文章**](https://kubernetes.io/blog/2018/06/27/kubernetes-1.11-release-announcement/)**的一部分**

## **介绍**



根据[Kubernetes 1.11版本的博客文章](https://kubernetes.io/blog/2018/06/27/kubernetes-1.11-release-announcement/)，我们宣布基于IPVS的群集内服务负载平衡已逐步升级为通用。在此博客中，我们将带您深入了解该功能。

## **什么是IPVS？**

IPVS（IP虚拟服务器）构建在Netfilter之上，作为Linux内核的一部分实现传输层负载平衡。

IPVS被合并到LVS（Linux虚拟服务器）中，它在一个主机上运行，并在一个真实服务器集群前充当负载平衡器。IPV可以将基于TCP和UDP的服务请求定向到真实服务器，并使真实服务器的服务在单个IP地址上显示为虚拟服务。因此，IPVS自然支持Kubernetes服务。

## **为什么**使Kubernetes使用IPVS？

随着Kubernetes使用量的增加，其资源的可伸缩性变得越来越重要。尤其是，服务的可伸缩性对于运行大型工作负载的开发人员/公司采用Kubernetes至关重要。

服务路由的构建模块Kube-proxy依靠经过艰苦努力的iptables来实现核心支持的服务类型，例如ClusterIP和NodePort。但是，iptables很难扩展到成千上万的服务，因为它纯粹是为防火墙目的而设计的，并且基于内核规则列表。

尽管Kubernetes在v1.6版本中已经支持5000个节点，但是带有iptables的kube代理实际上是将集群扩展到5000个节点的瓶颈。一个例子是，对于5000节点集群中的NodePort服务，如果我们有2000个服务，每个服务有10个pod，这将导致每个工作节点上至少有20000条iptable记录，这会使内核相当繁忙。

另一方面，在集群服务中使用基于ipv的负载平衡对于这种情况有很大帮助。IPVS是专门为负载平衡而设计的，它使用了更高效的数据结构（哈希表），允许几乎无限的规模。 

## 基于IPVS的Kube代理

### 参数更改

参数：代理模式，除了现有的用户空间和IPTABLE模式之外，IPVS模式是通过代理代理模式IPVS配置的。它隐式地使用IPVS NAT模式进行服务端口映射。

参数：–ipvs调度程序              

添加了一个新的kube代理参数来指定IPVS负载平衡算法，参数是--IPVS scheduler。如果未配置，则循环（rr）是默认值。

- rr：循环
- lc：最少连接
- dh：目标哈希
- sh：源哈希
- sed：最短的预期延迟
- nq：永不排队

在将来，我们可以实现特定于服务的调度程序（可能通过注释），它具有更高的优先级并覆盖值。

参数：-清除IPV类似于--cleanup iptables参数，如果为true，则清除在IPV模式下创建的IPV配置和iptables规则。

参数：- IPVS同步周期，即IPVS规则刷新的最大间隔（例如“5s”、‘1m’）。必须大于0。

参数：-ipvs最小同步周期刷新ipvs规则的最小间隔（例如“5s”、“1m”）。必须大于0。

参数：- IPVS排除CIDR（CIDR）的一个逗号分隔的列表，IPVS PROXIDER在清理IPVS规则时不应该触摸，因为IPVS PROXIER不能区分Kube代理创建的IPVS规则与用户原始IPVS规则。如果您在环境中使用IPVS PROXIER与您自己的IPVS规则，则应该指定此参数，否则将清除原始规则。

### 设计注意事项

#### IPVS服务网络拓扑

当创建CuultSIP类型服务时，IPVS PROXIER将做以下三件事：

- 确保节点中存在一个虚接口，默认为KUBE-IPVS0       
- 将服务IP地址绑定到虚拟接口    
- · 分别为每个服务IP地址创建IPV虚拟服务器

这里有一个例子：

```go
# kubectl describe svc nginx-service
Name:			nginx-service
...
Type:			ClusterIP
IP:			    10.102.128.4
Port:			http	3080/TCP
Endpoints:		10.244.0.235:8080,10.244.1.237:8080
Session Affinity:	None

# ip addr
...
73: kube-ipvs0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN qlen 1000
    link/ether 1a:ce:f5:5f:c1:4d brd ff:ff:ff:ff:ff:ff
    inet 10.102.128.4/32 scope global kube-ipvs0
       valid_lft forever preferred_lft forever

# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn     
TCP  10.102.128.4:3080 rr
  -> 10.244.0.235:8080            Masq    1      0          0         
  -> 10.244.1.237:8080            Masq    1      0          0   
```

请注意，Kubernetes服务和IPVS虚拟服务器之间的关系是1:N。例如，考虑具有多个IP地址的Kubernetes服务。外部IP类型服务有两个IP地址-ClusterIP和外部IP。然后将创建2个虚拟服务器，一个用于集群IP，另一个用于外部IP。Kubernetes端点（每个IP+端口对）和IPVS虚拟服务器之间的关系是1:1。

删除Kubernetes服务将触发删除对应的IPVS虚拟服务器、IPVS真实服务器及其绑定到虚拟接口的IP地址。

#### 端口映射

IPVS中有三种代理模式：NAT（masq）、IPIP和DR。只有NAT模式支持端口映射。Kube代理利用NAT模式进行端口映射。以下示例显示IPVS将服务端口3080映射到Pod端口8080。

```go
TCP  10.102.128.4:3080 rr
  -> 10.244.0.235:8080            Masq    1      0          0         
  -> 10.244.1.237:8080            Masq    1      0      
```

#### 会话关联

IPV支持客户端IP会话关联（持久连接）当服务指定会话关联时，IPVS PROXIER将在IPVS虚拟服务器中设置超时值（默认值为180MIN＝10800）。例如：

```go
# kubectl describe svc nginx-service
Name:			nginx-service
...
IP:			    10.102.128.4
Port:			http	3080/TCP
Session Affinity:	ClientIP

# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.102.128.4:3080 rr persistent 10800
```

#### IPVS和IPSET在IPVS PROXIER中的应用

IPVS用于负载平衡，它不能处理kube代理中的其他解决方法，例如包过滤、发夹伪装技巧、SNAT等。

IPVS PROXIER利用上述方案中的IPTABLE。具体而言，IPVS PROXIER将回落到IPTHOST以下4个场景：

- ·kube代理从-伪装所有=真开始     
- · 在kube代理启动中指定集群CIDR              
- 支持负载均衡器类型服务 
- · 支持NodePort类型服务

但是，我们不想创建太多iptables规则。因此我们采用ipset来减少iptables规则。以下是IPvPROXIER维护的IPSET集合表：

| 设置名称                       | 成员                                                  | 用法                                                         |
| :----------------------------- | :---------------------------------------------------- | :----------------------------------------------------------- |
| KUBE-CLUSTER-IP                | 所有服务IP +端口                                      | 为`masquerade-all=true`或`clusterCIDR`指定情况化妆舞会       |
| KUBE-LOOP-BACK                 | 所有服务IP +端口+ IP                                  | 化装发夹问题的化装舞会                                       |
| KUBE-EXTERNAL-IP               | 服务外部IP +端口                                      | 伪装到外部IP的数据包                                         |
| KUBE-LOAD-BALANCER             | 负载均衡器入口IP +端口                                | 将数据包伪装成负载均衡器类型的服务                           |
| KUBE-LOAD-BALANCER-LOCAL       | 负载均衡器入口IP +端口 `externalTrafficPolicy=local`  | 接受数据包到负载均衡器 `externalTrafficPolicy=local`         |
| KUBE-LOAD-BALANCER-FW          | 负载均衡器入口IP +端口 `loadBalancerSourceRanges`     | `loadBalancerSourceRanges`指定的负载均衡器类型服务的丢包     |
| KUBE-LOAD-BALANCER-SOURCE-CIDR | 负载均衡器入口IP +端口+源CIDR                         | 接受具有`loadBalancerSourceRanges`指定的负载均衡器类型服务的数据包 |
| KUBE-NODE-PORT-TCP             | NodePort类型服务TCP端口                               | 伪装到NodePort（TCP）的数据包                                |
| KUBE-NODE-PORT-LOCAL-TCP       | NodePort类型服务TCP端口 `externalTrafficPolicy=local` | 通过以下方式接受到NodePort Service的数据包 `externalTrafficPolicy=local` |
| KUBE-NODE-PORT-UDP             | NodePort类型服务UDP端口                               | 伪装到NodePort（UDP）的数据包                                |
| KUBE-NODE-PORT-LOCAL-UDP       | NodePort类型服务UDP端口 `externalTrafficPolicy=local` | 通过以下方式接受到NodePort Service的数据包 `externalTrafficPolicy=local` |

一般来说，对于IPVS PROXIER，不管我们有多少服务/ PODS，IPTABLE规则的数量是静态的。

### 在IPVS模式下运行kube代理

目前，本地up脚本、GCE脚本和kubeadm支持通过导出环境变量（KUBE_proxy_mode=IPVS）或指定标志（--proxy mode=IPVS）来切换IPVS代理模式。在运行IPVS PROXIER之前，请确保已经安装了IPVS所需的内核模块。

```go
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack_ipv4
```

最后，对于Kubernetes v1.10，默认情况下SupportIPVSProxyMode将功能门设置为true。对于Kubernetes v1.11，功能门已被完全删除。但是，您需要--feature-gates=SupportIPVSProxyMode=true在v1.10之前显式启用Kubernetes。

## 参与其中

参与Kubernetes的最简单方法是加入符合您的兴趣的众多[特殊兴趣小组](https://github.com/kubernetes/community/blob/master/sig-list.md)（SIG）之一。您有什么想向Kubernetes社区广播的内容吗？在我们的每周[社区会议上](#weekly-meeting)，以及通过以下渠道分享您的声音。

感谢您一直以来的反馈和支持。在[Stack Overflow](http://stackoverflow.com/questions/tagged/kubernetes)上发布问题（或回答问题）， 在[K8sPort ](http://k8sport.org/)[上](http://stackoverflow.com/questions/tagged/kubernetes)加入倡导者社区门户， 在Twitter [@Kubernetesio](https://twitter.com/kubernetesio)上关注我们以获取最新更新。在[Slack](http://slack.k8s.io/)上与社区聊天 分享您的Kubernetes [故事](https://docs.google.com/a/linuxfoundation.org/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform)







原文链接：https://kubernetes.io/blog/2018/07/09/ipvs-based-in-cluster-load-balancing-deep-dive/

