用Prometheus监控Kubernetes-最终指南（part 1）

原文作者：Mateo Burillo
原文地址：[Kubernetes Monitoring with Prometheus -The ultimate guide (part 1)](https://sysdig.com/blog/kubernetes-monitoring-prometheus/)

Prometheus监控正迅速成为Docker和Kubernetes的监控工具之一。本指南介绍如何使用Prometheus实现kubernetes监控。你可以学到如何部署Prometheus服务器、metrics exporters、设置Kube-state-metrics、提取、删除和收集Metric、使用Alertmanager配置警报以及使用
Grafana配置仪表板。我们将介绍如何手动执行此操作，以及如何利用一些自动部署/安装方法（如Prometheus Operators）。

本指南由四部分组成：

1-（这里）

+ Prometheus及其核心概念简介
+ Prometheus与其他监控解决方案比较
+ 如何安装Prometheus
+ 监控Kubernetes服务
  + Prometheus exporters
+ 监控Kubernetes群集
  + Kubernetes节点
  + Kube State Metrics
+ Kubernetes内部组件

2- 如何在Kubernetes中配置和运行Prometheus技术栈的其他组件：Alertmanager、Push gateway、Grafana、外部存储器、警报接收器。

3- Prometheus operator、自定义资源类型、Prometheus的自动Kubernetes部署、AlertManager和Grafana。

4-Prometheus的性能考虑，高可用性，外部存储，维度限制。

# “使用#Prometheus监控你的#Kubernetes集群，构建涵盖Kubernetes集群组件、部署的微服务、警报和仪表板的完整堆栈（1/4）。”

## 为什么用Prometheus监测Kubernetes

发生了两次技术演进，需要一个新的监控框架：

 + **DevOps文化**：在DevOps出现之前，监控框架由主机、网络以及相关服务组成。而现在，因为开发人员要更多地参与到CI/CD pipeline中并进行很多项操作调试，所以他们希望能轻松地将应用程序和与业务相关的Metric集成为基础设施的有机组成部分。监控需要大众化，使之更容易访问，并覆盖堆栈的其他层。
 + **容器和Kubernetes**：基于容器的基础设施正在从根本上改变我们如何进行日志记录、调试、高可用性……而监控也不例外。现在你有了大量不稳定的软件实体、服务、虚拟网络地址、公开的Metric，它们会突然出现或消失。传统的监控工具并不是用来处理这个问题的。
 + **多维数据模型**：该模型基于key-value pairs，类似于Kubernetes使用标签（label）组织基础设施元数据。它支持灵活、准确的时间序列数据，支持Prometheus查询语言。
 + **可访问的格式和协议**：发布kubernetes Metric是一项非常简单的事。Metric是我们可读的，采用自解释格式，并使用标准HTTP传输发布。您可以使用Web浏览器检查Metric是否正确发布：
![](https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/prom_kubernetes_metrics-768x176.png)

 + **服务发现**：Prometheus服务器负责周期性地获取目标，这样应用程序和服务就不必担心数据的发布（metric是提取的，而不是推送的）。这些Prometheus服务器有几种自动发现（autodiscover mechanisms）scrape目标的方法，其中一些可以配置为筛选和匹配的容器元数据，使得这些Prometheus服务器非常适合短暂的Kubernetes工作负载。
 + **模块化和高可用性组件**：Metric收集、警报、图形可视化等由不同的可组合服务执行。所有这些服务都是为防止冗余和分片而设计的。

## Prometheus与其他Kubernetes监控工具的比较

Prometheus在2016年发布了1.0版，所以这是一项相当新的技术。当Prometheus第一次出现的时候，有很多经过测试的监控工具。Prometheus与其他资深监控项目相比如何？

**Key-value与dot-separated dimensions**：部分引擎（如Statsd/Graphite）使用显式点分隔格式来表示尺寸，有效地为每个标签生成一个新的metric：

```
current_active_users.free_tier = 423
current_active_users.premium = 56
```
当尝试公开高维数据（每个metrics包含许多不同的标签）时，此方法可能会变得很麻烦。基于查询的灵活聚合也变得更加困难。

假设你有10台服务器，并且希望按错误代码分组。使用key-value，你可以简单地通过`{http_code=“500”}`对flat  metric进行分组。使用dot-separated dimensions，你将拥有大量独立的metric ，需要使用表达式聚合这些metric 。

**Event logging与metrics recording**：InfluxDB/Kapacitor更类似于Prometheus堆栈。他们使用基于标签的维度和相同的数据压缩算法。不过，由于Inflix具有纳秒级的时间分辨率并且能够合并不同的event logs，因而它更适合event logging。Prometheus更适合于metrics收集，它有一个更强大的查询语言来检查metrics。

**Blackbox与whitebox monitoring**：如前所述，Nagios/Icinga/Sensu之类的工具适合于主机/网络/服务监控，传统的系统管理任务。例如，Nagios是基于主机的。如果你想获得有关微服务（也称为[whitebox monitoring](https://insights.sei.cmu.edu/devops/2016/08/whitebox-monitoring-with-prometheus.html)）状态的内部详细信息，Prometheus是一个更合适的工具。

## Prometheus微服务和Kubernetes监控的挑战
想要部署可靠的监视/警报/绘图体系结构，需要解决监控kubernetes集群所特有的一些问题。

### 监控容器：可见性

容器是轻量级的，主要是不能改变的黑箱，它可能带来监视挑战...Kubernetes API和[kube-state-metrics](https://github.com/kubernetes/kube-state-metrics)（它本身使用Prometheus metrics）通过公开Kubernetes内部数据（如期望/在部署中运行副本的数量，不可调度的节点等。）来解决这个问题的一部分。

Prometheus非常适合微服务，因为你只需要公开一个metrics端口，因此不需要增加太多复杂性或运行其他服务。通常，服务本身已经呈现了一个HTTP接口，开发人员只需要添加一个额外的路径，比如`/metrics`。

在某些情况下，服务器不准备为Prometheus metrics服务，而且你也不能通过修改代码来协助它。在这种情况下，你需要部署与服务器捆绑在一起的[Prometheus exporter](https://prometheus.io/docs/instrumenting/exporters/)，它通常作为同一个pod的sidecar容器。

### 动态监控：时刻变化、不稳定的基础设施

对于传统静态的监控系统而言，短暂的entities(能随时启动或停止报告)是个问题。

Prometheus有几种[自动发现机制（autodiscover mechanisms）](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)来处理这个问题。与本指南最相关的是：

**Consul**：用于服务发现和配置的工具。Consul具有分布式、高可用性、扩展性极强的优点。

**Kubernetes**：Kubernetes SD配置允许从Kubernetes的REST API检索scrape目标，并始终与集群状态保持同步。

**Prometheus Operator**：根据熟悉的Kubernetes查询标签（label）自动生成监控目标配置。稍后我们将重点讨论此部署选项。

### 监视新的基础结构层：Kubernetes组件

使用Kubernetes观念（如物理主机或服务端口）变得不那么重要。你需要围绕不同的分组来组织监控，如微服务性能（不同的pod分散在多个节点上）、命名空间、部署版本等。

使用Prometheus基于标签的数据模型和PromQL，你可以很容易地适应这些新的范围。

## Kubernetes的Prometheus监控：架构概述

稍后我们将更详细地介绍，此图涵盖了要在Kubernetes集群中部署的基本实体：

![](https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/prometheus_kubernetes_diagram_overview.png)

+ 1–Prometheus服务器需要尽可能多的自动发现目标。
 + 有多种选择可以实现该目标：
   + Consul
   + Prometheus Kubernetes SD插件
   + Prometheus操作人员及其自定义资源类型
+ 2-除了应用程序的metrics之外，我们还希望Prometheus收集与Kubernetes服务、节点和编排状态相关的metrics。
 + Node exporter，用于传统的主机相关metrics：cpu、mem、网络等。
 + Kube-state-metrics，用于编排和集群级metrics：部署、pod metrics、资源预留等。
 + 来自内部组件的Kube-system metrics：kubelet、etcd、dns、调度器等。
+ 3–Prometheus可以使用PromQL规定触发警报的规则，AlertManager将负责管理警报通知、分组、阻断等。
+ 4–AlertManager组件配置接收器和网关以传递警报通知。
+ 5—Grafana可以从任意数量的Prometheus服务器、显示面板和仪表板中提取metrics。

## 如何安装Prometheus

在主机或Kubernetes集群中安装Prometheus的方法有很多：
 + 直接作为一个主机上的二进制文件运行，对于学习、测试和开发都很好，但不适合容器化部署。
 + 作为一个Docker容器，依次有几个编排选项：
  + Raw Docker容器、Kubernetes Deployments / StatefulSets、Helm Kubernetes package manager、Kubernetes operators等。

  从手动的部署过渡到自动化的部署：

  单二进制->Docker容器->Kubernetes Deployment->Prometheus operator（第3章）

你可以直接在你的主机上下载和运行Prometheus二进制文件：

```
prometheus-2.3.1.linux-amd64$ ./prometheus
level=info ts=2018-06-21T11:26:21.472233744Z caller=main.go:222 msg="Starting Prometheus"
```
这可能会让用户对Prometheus网络接口（默认端口9090）留下不错的第一印象。

还有一个更好的选择是在容器中部署Prometheus服务器：

```
docker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus/prometheus.yml 
       prom/prometheus
```

需要注意的是，你可以很容易地将这个Docker容器调整为一个合适的Kubernetes Deployment对象，该对象将从ConfigMap装载配置、公开服务、部署多个副本等。

```
kubectl create configmap prometheus-example-cm --from-file prometheus.yml
```

（这里有一个基础的Prometheus.yml配置文件）

然后你可以应用这个例子yaml：

如果你不想配置一个负载均衡器/外部IP，那么你可以将NodePort作为指定服务类型。

几秒钟后，你应该会看到Prometheus pods在你的集群中运行：

```
kubectl get pods
NAME                                     READY     STATUS    RESTARTS   AGE
prometheus-deployment-68c5f4d474-cn5cb   1/1       Running   0          3h
prometheus-deployment-68c5f4d474-ldk9p   1/1       Running   0   
```

这时你可以实现几种配置调整，例如配置pod反亲和性（antiaffinity）来强制Prometheus server pods位于不同的节点中。我们将在本指南的第四章中介绍性能和高可用性方面。

使用Prometheus operator是一个更加先进和自动化的选择，这将在本指南的第三章中介绍。你可以将其视为元部署：一种部署管理其他部署并根据高级服务规范配置和更新它们的部署。我们将开始手动配置Prometheus堆栈，在下一章中，我们将用operator让Prometheus Deployment易于移植、声明并且更加灵活。

## 如何用Prometheus监控Kubernetes服务

Prometheus metrics是由服务通过HTTP（S）公开的，与其他类似的监控解决方案相比，这种方法有几个优点：
+ 不需要安装代理服务，只需公开Web端口。Prometheus服务器将定期进行删除（提取）操作，因此你也不必担心推送metrics或配置远程端点。
+ 一些微服务已经使用HTTP来实现其常规功能，你可以重复使用该内部web服务器，只需添加一个类似`/metrics`的文件夹。
+ metrics格式本身是可读的，并且易于理解。如果你是微服务代码的维护者，则可以开始发布metrics，而没有太多复杂性或学习需求。

一些服务被设计为从一开始就公开Prometheus metrics（Kubernetes-kubelet、traefik-web代理、istio-microservice-mesh等）。其他一些服务不是本地集成的，但是可以使用exporter轻松地进行调整。exporter是一种收集服务统计信息并“转换”为Prometheus metrics的服务。这一章有两个例子。

从最好的情况开始：你正在部署的微服务已经提供了一个Prometheus端点。

Traefik是一个反向代理，旨在与微服务和容器紧密集成。Traefik的一个常见用例是用作入口控制器或入口点，这是网络和集群内特定微服务之间的桥梁。

有多种方式安装Traefik和Kubernetes-特殊的安装指南。如果你只是想用Prometheus支持快速启动并运行一个简单的Traefik deployment，请使用以下代码片段：
```
kubectl create -f https://raw.githubusercontent.com/mateobur/prometheus-monitoring-guide/master/traefik-prom.yaml
```

一旦Traefik pods正在运行，你就可以显示它的服务IP：
```
kubectl get svc
NAME                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                   AGE
kubernetes                   ClusterIP   10.96.0.1       <none>        443/TCP                   238d
prometheus-example-service   ClusterIP   10.103.108.86   <none>        9090/TCP                  5h
traefik                      ClusterIP   10.108.71.155   <none>        80/TCP,443/TCP,8080/TCP   35s
```
你可以用Purl检查公开的Prometheus metrics：

```
curl 10.108.71.155:8080/metrics
# HELP go_gc_duration_seconds A summary of the GC invocation durations.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 2.4895e-05
go_gc_duration_seconds{quantile="0.25"} 4.4988e-05
...
```

现在，需要将新目标添加到`prometheus.yml` conf文件中。

你会注意到Prometheus会自动删除自己：

```
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']
```

添加另一个静态端点：

```
 - job_name: 'traefik'
    static_configs:
    - targets: ['traefik:8080']
```

如果服务位于不同的命名空间中，则需要使用FQDN（即`traefik.default.svc.cluster.local`）

当然，这是一个简单的最小配置，scrape配置支持多个参数。

举几个例子：

+ `basic_auth`和`bearer_token`：你的端点可能需要通过HTTPS进行身份验证，使用传统的登录/密码方案或请求头(request headers)中的bearer token。
+ `kubernetes_sd_configs`或`consu_sd_configs`:不同的端点自动发现方法。
+ `scrape_interval`、`scrape_limit`、`scrape_timeout`：精度、弹性和系统负载之间的不同权衡。

由于部署的Prometheus技术栈变得更加完整，我们将在下一章中使用其中的一些。

修补ConfigMap和部署（Deployment）：

```
kubectl create configmap prometheus-example-cm --from-file=prometheus.yml -o yaml --dry-run | kubectl apply -f -

kubectl patch deployment prometheus-deployment -p 
  "{"spec":{"template":{"metadata":{"labels":{"date":"`date +'%s'`"}}}}}"
```

如果你访问Prometheus Web界面中的`/targets` URL，你应该会看到Traefik端点UP：

![](https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/prometheus_kubernetes_traefik-768x360.png)

使用Web主界面，我们可以找到一些Traefik metrics（很少有，因为我们没有为这个示例配置的Traefik前端或后端），并检索其值：

![](https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/prometheus_kubernetes_traefik-2-1.png)

我们已经有一个Prometheus在Kubernetes上工作的例子！

## 如何使用Prometheus Exporters监控Kubernetes服务,使用Prometheus Exporters监控应用程序?

很可能，你想要在Kubernetes集群中部署的许多应用程序并没有立即公开Prometheus metrics。这种情况下，你需要捆绑一个Prometheus exporter，这是一个能够检索主服务的状态/日志/其他metrics格式并将此信息公开为Prometheus metrics的附加进程。换句话说，它是Prometheus的适配器。

你可以用下列命令部署包含redis服务器和Prometheus siDeCar容器的pod：

```
# Clone the repo if you don't have it already
git clone git@github.com:mateobur/prometheus-monitoring-guide.git
kubectl create -f prometheus-monitoring-guide/redis_prometheus_exporter.yaml
```

如果显示redis pod，你可以注意到里面有两个容器：

```
kubectl get pod redis-546f6c4c9c-lmf6z
NAME                     READY     STATUS    RESTARTS   AGE
redis-546f6c4c9c-lmf6z   2/2       Running   0          2m
```


现在，只需要更新Prometheus的配置并重新加载，就像我们在上一节中所做的那样：

```
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:9121']
```

获取所有redis service metrics：

![](https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/prometheus_kubernetes_redis-1-768x478.png)
如何用Prometheus监控Kubernetes应用程序

## 用Prometheus和kube-state-metrics监控Kubernetes集群

除了监控部署在集群中的服务外，还需要监控Kubernetes集群本身。要考虑的集群监控的三个方面是：
+ Kubernetes主机（节点）–传统的系统管理指标，如cpu、负载、磁盘、内存等。
+ 业务流程级别的metrics—部署状态、资源请求、调度和API服务器延迟等。
+ 内部 kube-system组件-调度器、控制管理器、dns服务等的详细服务metrics。

Kubernetes内部监控架构最近经历了一些变化，我们将其总结在了这里，以便你可以了解更多的信息，你可以阅读它的[设计方案](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/monitoring_architecture.md)。

## 在Prometheus堆栈上监控kubernetes组件

**Heapster**：Heapster是一个集群范围内的聚合器，其中包含作为集群中的pod运行的监控和事件数据。

![](https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/kubernetes_monitoring_heapster.png)

除了Kubelets/cAdvisor端点之外，还可以将额外的metrics sources追加到Heapster——类似于kube-state-metrics（见下文）中。

Heapster现在已被**弃用**，它的替代品是metrics-server。

**cAdvisor**：cAdvisor是一个开源的容器资源使用和性能分析代理。它是专门为容器而构建的，并在本地支持Docker容器。在Kubernetes中，cAdvisor作为kubelet二进制文件的一部分运行，任何检索节点本地和Docker metrics的聚合器都将直接删除kubelet-prometheus端点。

**Kube-state-metrics**：kube-state-metrics是一个简单的服务，它监听Kubernetes API服务器，并生成有关对象（如部署、节点和pod）状态的metrics。需要注意的是，kube-state-metrics只是一个metrics端点，其他实体需要对其进行清理并提供长期存储（即Prometheus服务器）。

**Metrics-serve**：Metrics-server是集群范围内的资源使用数据聚合器。它将作为默认的堆处理器替换。同样，Metrics-server将只显示最后的数据点，而不负责长期存储。

因此：

+ Kube-state metrics侧重于编排元数据：部署、pod、副本状态等。

+ Metrics-server专注于实现resource metrics API：CPU、文件描述符、内存、请求延迟等。

##  用Prometheus监控Kubernetes节点

Kubernetes节点或主机需要被监控，我们有很多工具来监控linux主机。在本指南中，我们将使用Prometheus node-exporter：

+ 它由Prometheus项目本身主办

+ 它是在下一章中使用Prometheus operator时自动部署的

+ 它可以作为DaemonSet部署，因此，如果从集群中添加或删除节点，将自动缩放。

有几个选项可以部署此服务，例如，使用此repo中的DaemonSet：

```
kubectl create ns monitoring 
kubectl create -f https://raw.githubusercontent.com/bakins/minikube-prometheus-demo/master/node-exporter-daemonset.yml
```

或使用Helm / Tiller：

如果要使用Helm，请记住在继续之前为tiller组件创建RBAC角色和服务帐户。

```
helm init --service-account tiller
helm install --name node-exporter stable/prometheus-node-exporter
```

一旦安装并运行chart，你就可以显示需要清理的服务：

```
kubectl get svc 
NAME                                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                     AGE
node-exporter-prometheus-node-exporter   ClusterIP   10.101.57.207    <none>        9100/TCP                                    17m
```

一旦像前面几节一样添加清理配置（scrape config），就可以开始收集和显示node metrics：

![](https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/prometheus_monitoring_kube_node-1-768x478.png)

用Prometheus监控Kube-state-metrics

部署和监控Kube-state-metrics也是一项非常简单的事。同样，你可以直接部署在下面的例子中，或者使用Helm chart。

```
git clone https://github.com/kubernetes/kube-state-metrics.git
kubectl apply -f kube-state-metrics/kubernetes/
...
kubectl get svc -n kube-system
NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
kube-dns             ClusterIP   10.96.0.10       <none>        53/UDP,53/TCP       13h
kube-state-metrics   ClusterIP   10.102.12.190    <none>        8080/TCP,8081/TCP   1h
```
同样，你只需要在Prometheus配置中清理该服务（端口8080）。记住这次使用FQDN：

```
  - job_name: 'kube-state-metrics'
    static_configs:
    - targets: ['kube-state-metrics.kube-system.svc.cluster.local:8080']
```

## 用Prometheus监测kubernetes内部组件

有几个Kubernetes组件，包括etcd、 kube-scheduler或kube-controller，可以用Prometheus公开其内部性能的metrics。

监控它们与监控任何其他Prometheus端点非常相似，有两个特点：

+ 这些进程用来监听哪些网络接口、http方案和安全性（HTTP, HTTPS, RBAC）取决于你的部署方法和配置模板。
  + 通常，这些服务只在主节点的localhost上监听，这使得它们很难从Prometheus pods中访问。
+ 这些组件可能没有Kubernetes服务指向pods，但你始终能创建它。

根据你的部署方法和配置，Kubernetes服务可能只监听本地主机，为了使本例中的操作更简单，我们将使用minikube。

minikube能让我们在几分钟内生成一个本地单节点Kubernetes虚拟机。

这在你的主集群、GKE、AWS等上也同样有效，但是你需要通过修改配置并重新启动服务或提供其他网络路由来访问服务端口。

安装minikube是一个相当简单的过程。首先安装二进制文件，然后创建在所有接口上公开kube-scheduler服务的集群：

```
ubelet.authentication-token-webhook=true --extra-config=kubelet.authorization-mode=Webhook --extra-config=scheduler.address=0.0.0.0 --extra-config=controller-manager.address=0.0.0.0
```
创建一个指向kube-scheduler pod的服务：

```
kind: Service
apiVersion: v1
metadata:
  name: scheduler-service
  namespace: kube-system
spec:
  selector:
    component: kube-scheduler
  ports:
  - name: scheduler
    protocol: TCP
    port: 10251
    targetPort: 10251
```
现在你就能够清理端点：`scheduler- service.kube system.svc.cluster.local:10251`

## 下一篇

我们已经有一个Prometheus部署，它有6个目标端点：2个“end-user”应用程序、3个Kubernetes集群端点以及Prometheus本身。这时配置仍然不是自动化的，但我们有一个正在运行的Prometheus基础设施。

下一章将介绍通常与Prometheus服务一起部署的其他组件。我们将开始使用PromQL语言来聚合metrics、触发警报和生成可视化仪表板。
