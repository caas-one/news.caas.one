# Kubernetes:极其实惠的个人项目平台

作者：Caleb Doxsey 原文连接：[Kubernetes: The Surprisingly Affordable Platform for Personal Projects](http://www.doxsey.net/blog/kubernetes--the-surprisingly-affordable-platform-for-personal-projects)

今年年初，我花了几个月的时间在Kubernetes上深入研究一个工作项目。Kubernetes是一款包括所有服务的，包括UPS在内的基础设施管理技术，它能解决你在大规模使用时遇到的许多问题。然而，流行的观点认为，Kubernetes是一种过于复杂的技术，只适合非常大的机器集群;它带来了巨大的操作负担，因此将它用于任何少于几十台的机器都是多余的。我认为那可能是错的（观点）。Kubernetes对于小型项目是有意义的，现在你可以用每月5美元的价格拥有自己的Kubernetes集群。

## 有关Kubernetes的案例

我将向您展示如何设置自己的Kubernetes集群，但首先我将尝试在小型项目中使用Kubernetes:

## Kubernetes是稳健的

乍一看，Kubernetes似乎有些过犹不及。只提供一个VM并将web应用程序配置为服务似乎很容易，所以为什么不这样做呢?走这条路会让你做出以下几个决定:

1. 如何部署应用程序?把它同步到服务器上?

2. 依赖关系呢?如果您使用python语言或ruby开放式程式语言，则必须将它们安装到服务器上。你打算手动运行这些命令吗?

3. 你将如何运行应用程序?你会简单地在后台启动二进制文件然后关闭它吗?这可能不是很好，所以如果你走服务路线，你需要学习启动服务对应的脚本文件目录吗?

4. 如何使用不同的域名或网站路径运行多个应用程序?(你可能需要设置负载均衡或服务器)

5. 假设你更新了应用程序。如何推出更改?停止服务，部署代码，重新启动服务?你会如何避免停机?

6. 如果你搞砸了部署怎么办?有办法转返吗?（符号链接一个文件夹. . ?这个简单的脚本听起来就不再那么简单了）

7. 你的应用程序是否使用了其他服务，例如缓存数据库?你会如何配置这些服务?

Kubernetes对所有这些问题都有解决方案。当然，还有其他方法可以解决这些问题，甚至可能是更好的方法，但是使用Kubernetes是一个可以使你尽可能少的考虑事情的方法，从而使你可以将精力集中在应用程序上。

## Kubernetes是可靠的

一台服务器最终肯定会宕机。这种情况很少见，可能一年一次，但是当它发生的时候，让事情重新回到工作状态真的是一件令人头疼的事。如果你只是简单地手动配置一些东西，这一点尤为正确。还记得上次运行的命令吗?你知道服务器在运行什么吗?我想起了著名的bash.org网站上的一句话:
> 
> <erno >嗯...我丢了一台机器。字面意义上的丢了。它虽然响应延迟，但它完全能工作，只是我不知道它在我公寓的哪里。          http://bash.org/?5273

最近在我的博客上就发生了这样的事情。我只是需要更新一个链接，我完全忘记了如何部署我的博客，最后只需10分钟的修复变成了整个周末。

Kubernetes使用一种描述性的格式，因此你总是知道应该运行什么东西，部署的构建块也更加清晰。此外，控制平面可以更好地处理节点故障并自动重新调度资料库系统规则。对于像网页应用程序这样的无状态服务，你也不需要担心可能会失败。

## Kubernetes并不比其他选择难学

Kubernetes没有遵循UNIX作业系统模型。它不适合一个测试导向的操作员语言体系。它不会只做一件事并把这件事做好。它是一个针对许多问题的全面解决方案，并且取代了开发人员可能习惯使用的许多技术和工具。

Kubernetes有自己的词汇表、工具以及自己的服务器范例，这与传统的UNIX操作系统非常不同。当你了解这些系统时，你会发现它们之间的许多差别似乎是任意的和过于复杂的;甚至是残忍的。我认为这种复杂性是基于很好的理由的，但我在这里想说的是Kubernetes并不简单易懂;相反，Kubernetes的知识足以构建和维护基础结构。

并不是每个人都有UNIX系统管理权限后台。大学毕业后，我花了5年时间研究Windows的生态系统。我可以告诉你的是，我的第一份工作是在一家初创公司使用Linux作业系统，这个转变并不容易。我不熟悉指令，特别是不习惯按照指令线执行几乎所有操作。我花了一段时间来学习如何使用这个平台，但是因为我学了它(在我已经做了一段时间的软件开发之后)，我清楚地记得这个过程是多么令人痛苦。

有了Kubernetes，你可以从零开始。完全可以在Kubernetes中提供服务，而不需要从SSH远端登入协定连接到服务器。你不需要学习如何启动服务对应的脚本文件目录;你不必知道什么是运行级别，或者它是groupadd还是addgroup;也不需要格式化磁盘。或者学习如何使用ps，亦或者，上帝保佑你。所有这些东西都是重要并且有用的，它们都不会消失。我非常尊重那些能够在UNIX作业系统环境中编写代码的系统管理员。但是，如果开发人员能够在不需要了解所有这些的情况下高效地提供基础结构，那不是很好吗?

是这样的：
```csharp
[Unit]
Description=The NGINX HTTP and reverse proxy server
After=syslog.target network.target remote-fs.target nss-lookup.target

[Service]
Type=forking
PIDFile=/run/nginx.pid
ExecStartPre=/usr/sbin/nginx -t
ExecStart=/usr/sbin/nginx
ExecReload=/usr/sbin/nginx -s reload
ExecStop=/bin/kill -s QUIT $MAINPID
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

 
真的比这更难:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx
spec:
  selector:
    matchLabels:
      run: my-nginx
  replicas: 1
  template:
    metadata:
      labels:
        run: my-nginx
    spec:
      containers:
      - name: my-nginx
        image: nginx
        ports:
        - containerPort: 80
```

这是最好的情况。如果您能够胜任地进行基础架构管理，那么就不需要手动维护服务器。你将使用某个工具来做这件事:ansible, salt, chef, puppet，等等。当然，要有效地使用Kubernetes，还需要学习很多东西，但这并不比学习其他方法难。

## Kubernetes是开源的

在一个无服务架构变得如此流行的时代，Kubernetes明显摆脱了供应商的束缚。至少有3个受欢迎的、易于使用的Kubernetes提供商(谷歌、亚马逊、微软)不太可能很快消失。还有许多公司成功地运营了自己的Kubernetes集群，每天都有更多的公司运营。如今，对大多数初创公司来说，从一开始就使用Kubernetes是一件不需要费脑筋的事情。

作为一个开源项目，它有良好的文档记录、稳定且受欢迎，并且可以彻底覆盖所有问题。当然会有bug和技术上的挑战，但请放心，有些人会以你可能永远也无法接近的方式来推动Kubernetes。他们的痛苦经历造就了你的收获，而且这种技术在未来几年内只会不断进步。

## Kubernetes规模

维护基础设施的挑战之一是，对于小型部署有意义的技术通常不会转化为大型部署。将一个二进制文件从系统控制程序连接到一个服务器，结束一个进程，然后重新启动，这在单个服务器上当然是可以做到的，但是一旦维护了多个服务器，追踪它们的变化就会变得非常困难，这就是为什么需要像chef或puppet这样的工具来管理基础设施。

但是选择错误的工具会让你陷入困境。突然间，master chef服务器无法处理1.000个服务器的负载。绿色/蓝色部署似乎不适合你的产品型号并且capistrano任务需要几个小时来完成。一旦你达到一定的规模，你需要停止你一直在做的，重新开始。如果你能摆脱无休无止的基础设施，使用一种可以根据你的需要扩展的技术，那不是很好吗?

Kubernetes很像一个SQL（结构化查询语言）数据库。SQL是多年来关于数据存储和如何有效地查询数据的众多经验的产物。你可能不需要一个像样的SQL数据库可以提供其十分之一的特性,如果你设定自己的自定义数据库，你可以构建更有效的数据库。但在绝大多数的情况下，一个SQL数据库不仅满足你的需要，而且大大提高了你的快速提交解决方案的能力。与文件支持的自定义数据结构相比，SQL模式和索引更容易使用——随着产品的增长和变化，数据结构很大程度上肯定会过时。但是，一个SQL数据库可能会在不可避免的重构过程中继续被使用。

Kubernetes也是这样的。你的副业项目可能永远不会发展到需要Kubernetes这样的技术来构建它的规模，但是如果你确实遇到了其中的某些问题，它就拥有你需要的所有工具，你将学到的技能可能对未来的项目非常有价值的。

## 建立你自己的Knbemetes集群

因此，我认为在小型项目中使用Kubernetes是非常有意义的，但前提是它易于安装且价格低廉。事实证明这两个都是正确的。有一些受管理的Kubernetes供应商可以处理维护Kubernetes主控制平面的复杂细节，而最近云基础设施的价格战意味着这些服务将出奇的便宜。

比如说，我们将使用谷歌的Kubernetes引擎(GKE)，但是如果你不喜欢使用谷歌，你也可以看看亚马逊(EKS)或微软(AKS)。为了建立我们的Kubernetes集群，我们需要:

	一个域名(-10S/yr，视域名而定)

	cloudflare提供的DNS托管(免费)

在GKE上的A3节点kubernetes集群 (-5S/mo)

	一个网页应用程序作为docker容器发布到谷歌容器注册表(GCR)(免费)

	一些配置Kubernetes的结构组件

另外，为了节省成本，我们不会使用谷歌的入口控制器。相反，我们将在每个节点上作为一个守护进程运行Nginx服务器，并构建一个自定义操作符，将工作节点的外部IP地址与美国Cloudflare同步。

### 谷歌设置

首先登录console.cloud.google.com，如果你还没有账号的话，就创建一个项目。您还需要设置一个计费帐户。然后转到hamburger菜单中的Kubernetes页面，创建一个新的集群。你要做的是:

为位置类型选择Zonal

	我使用us-central 1-a作为我的专区

	选择你的kubernetes版本

	使用最便宜的实例类型(f1-micro)创建一个3节点

	对于该节点池，在先进的屏幕中，将启动盘大小设置为10GB，启用可抢占节点(它们更便宜)，启用自动升级和自动修复

	在节点池下面有一些附加选项。我们想要关闭HTTP负载平衡（负载平衡在GCP中很昂贵），也关闭所有的StackDriver的东西(也可能是昂贵的，以我的经验看是不太可靠的)，同样也要关闭kubernetes仪表板
设置了所有这些选项之后，就可以继续创建集群了。这里是成本的纲要:

	Kubernetes控制平面:免费，因为谷歌不向硕士收费

	Kubernetes工作节点:5.04美元/月，3个微节点通常是11.65美元/月，通过使混合电磁可抢占，我们将其降低到7.67美元/
月，并且对于“永久免费”层，它是5.04美元
	
存储费用:免费，存储费用可以在GCP中累计。我们免费获得30GB的持久磁盘，因此我们选择10GB的大小

	负载平衡器成本:免费，我们禁用HTTP负载平衡，因为仅这一项每个月就会花费18美元。相反，我们将在每个节点上运行我们自己的HTTP代理服务器，并将域名服务器指向公共IP地址

	网络费用:免费，只要你保持低于每个月1GB，出口就会是免费的。(之后是每GB 8美分)

因此，我们可以建立一个拥有3个节点的Kubernetes集群，其价格与单个数字海洋机器。

相同除了设置GKE外，我们还需要添加一些防火墙规则来允许外界访问我们节点上的HTTP端口。从hamburger菜单，转到VPC网络。防火墙规则为TCP端口80和443添加了规则，IP范围为0.0.0.0/0。
![](http://www.doxsey.net/assets/img/kubernetes-firewall-rules.png)

### 本地设置

启动并运行集群后，我们现在可以对其进行配置。按照cloud.google.com/sdk/docs上的说明安装gcloud工具。安装后，您可以通过运行以下命令来设置：

```yaml
gcloud auth login
```

 
如果你也想要安装docker，把它连接到GCR，这样你就可以推动容器:
```yaml
gcloud auth configure-docker
```

 
你还可以按照这里的说明安装和设置kubectl。最基本的:
```yaml
gcloud components install kubectl
gcloud config set project PROJECT_ID
gcloud config set compute/zone COMPUTE_ZONE
gcloud container clusters get-credentials CLUSTER_NAME
```

 
顺便说一句，这个工具在Windows、OSX或Linux中都能使用，这真是太棒了。作为偶尔使用windows的用户，这种情况是非常少的。

## 创建Web应用程序

欢迎你在自己的网页应用程序使用任何你喜欢的编程语言。本地编辑将杂乱的细节抽离出来。我们只需要构建一个监听端口的http应用程序。就我个人而言，我更喜欢在Go中构建这些应用程序，但为了多样化，我们可以尝试一下crystal。创建一个 main. cr. 文件:

```yaml
# crystal-www-example/main.cr
require "http/server"

Signal::INT.trap do
  exit
end

server = HTTP::Server.new do |context|
  context.response.content_type = "text/plain"
  context.response.print "Hello world from crystal-www-example! The time is #{Time.now}"
end

server.bind_tcp("0.0.0.0", 8080)
puts "Listening on http://0.0.0.0:8080"
server.listen
```

 
我们还需要一个Docker文件夹:

```yaml
# crystal-www-example/Dockerfile
FROM crystallang/crystal:0.26.1 as builder

COPY main.cr main.cr

RUN crystal build -o /bin/crystal-www-example main.cr --release

ENTRYPOINT [ "/bin/crystal-www-example" ]
```

 
我们可以建立和测试我们的web应用程序运行:

```yaml
docker build -t gcr.io/PROJECT_ID/crystal-www-example:latest .
docker run -p 8080:8080 gcr.io/PROJECT_ID/crystal-www-example:latest
```

 
然后在浏览器中访问localhost:8080。有了这种工作，我们可以推动我们的应用程序到GCR运行:

```yaml
docker push gcr.io/PROJECT_ID/crystal-www-example:latest
```

 
## 配置Kubernetes

我可以在这里找到自己的Kubernetes配置。

对于本例，我们将创建几个结构组件文件来表示各种服务，然后运行kubectl apply 在集群中配置它们。Kubernetes配置是描述性的，这些组件文件传达给Kubernetes我们希望看到的状态。我们把这个问题留给Kubernetes去解决。总的来说，我们要做的是:

	为我们的crystal-www-example网页应用程序创建部署和服务

	为服务器创建守护程序集和配置映射

	运行自定义应用程序来同步域名服务器的节点IP和Cloudflare

### Web应用程序配置

首先，让我们配置我们的web应用程序:(确保将PROJECT_ID替换为您的项目id)

```yaml
# kubernetes-config/crystal-www-example.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crystal-www-example
  labels:
    app: crystal-www-example
spec:
  replicas: 1
  selector:
    matchLabels:
      app: crystal-www-example
  template:
    metadata:
      labels:
        app: crystal-www-example
    spec:
      containers:
      - name: crystal-www-example
        image: gcr.io/PROJECT_ID/crystal-www-example:latest
        ports:
        - containerPort: 8080

---

kind: Service
apiVersion: v1
metadata:
  name: crystal-www-example
spec:
  selector:
    app: crystal-www-example
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
```

 
这将创建一个部署，它传达给Kubernetes创建pod小群聚和服务的指令，其中一个集装箱运行docker集装箱，另一个服务用于在集群中的服务搜索。要应用这个配置运行(从kubernets -config文件夹):
 
 ```yaml
kubectl apply -f .
```

我们可以通过这样使用来测试它的运行：
 
 ```yaml
kubectl get pod
# you should see something like:
# crystal-www-example-698bbb44c5-l9hj9          1/1       Running   0          5m
```

我们也可以创建一个代理APl，这样我们就可以访问它:

```yaml
kubectl proxy
```

 
然后访问：http://localhost:8001/api/v1/namespaces/default/services/crystal-www-example/proxy/

### NGINX配置

通常在Kubernetes中使用HTTP服务时，你会使用一个入口控制器。遗憾的是，谷歌的HTTP负载均衡器非常昂贵，因此我们将运行自己的HTTP代理服务器并手动配置它。(这并没有听起来那么难)

我们将为此使用一个守护程序集和一个配置映射。守护进程集是在每个节点上运行的应用程序。配置映射基本上是一个小文件，我们可以把它安装到集装箱中，它是我们存储服务器配置的地方。yaml结构组件是这样的:
 
 ```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - image: nginx:1.15.3-alpine
        name: nginx
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        volumeMounts:
        - name: "config"
          mountPath: "/etc/nginx"
      volumes:
      - name: config
        configMap:
          name: nginx-conf

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-conf
data:
  nginx.conf: |
    worker_processes 1;
    error_log /dev/stdout info;

    events {
      worker_connections 10;
    }

    http {
      access_log /dev/stdout;

      server {
        listen 80;
        location / {
          proxy_pass http://crystal-www-example.default.svc.cluster.local:8080;
        }
      }
    }
```

 
你可以看到我们如何将配置映射的 nginx. conf安装到nginx集装箱中。我们还在规则上设置了两个额外的字段，hostNetwork: true，这样我们就可以绑定主机端口并从外部 dnsPolicy: ClusterFirstWithHostNet 到达nginx服务器,这样我们就可以到达集群内部的服务器。这样一来它就是相当标准的配置。

应用这些更改，您应该能够通过访问节点的公共ip来访问nginx服务器。你可以通过这样运行发现： 

```yaml
kubectl get node -o yaml
# look for:
# - address: ...
#   type: ExternalIP
```


所以网页应用现在就可以通过互联网访问。剩下的就是给它起个好听的名字。

DNS连结我们需要为我们的集群节点设置3个DNS记录:

![](http://www.doxsey.net/assets/img/kubernetes-cloudflare-dns.png)
 
然后添加一个CNAME条目来指向那些A记录。(例如www.example.com照映kubernetes.example.com)我们可以手动执行此操作，但最好是自动执行，这样的话，如果我们扩展或替换节点，DNS记录将自动更新。

我认为这也是一个很好的例子，你可以让Kubernetes为你服务，而非对抗它。Kubernetes是完全可以编写脚本的，并且有一个强大的API，因此你可以使用不太难编写的自定义组件来填补空白。我为此开发了一个小型Go应用程序，你可以在这里找到:kubernetes-cloudflare-sync.

我开始建立一个informer程序:

```javascript
factory := informers.NewSharedInformerFactory(client, time.Minute)
lister := factory.Core().V1().Nodes().Lister()
informer := factory.Core().V1().Nodes().Informer()
informer.AddEventHandler(cache.ResourceEventHandlerFuncs{
  AddFunc: func(obj interface{}) {
    resync()
  },
  UpdateFunc: func(oldObj, newObj interface{}) {
    resync()
  },
  DeleteFunc: func(obj interface{}) {
    resync()
  },
})
informer.Run(stop)
```

 
每当一个节点被改变都会调用同步功能。然后我使用Cloudflare API rary (github.com/clouo lare-go)对IPs进行同步，如下所示:
 
 ```javascript
var ips []string
for _, node := range nodes {
  for _, addr := range node.Status.Addresses {
    if addr.Type == core_v1.NodeExternalIP {
      ips = append(ips, addr.Address)
    }
  }
}
sort.Strings(ips)
for _, ip := range ips {
  api.CreateDNSRecord(zoneID, cloudflare.DNSRecord{
    Type:    "A",
    Name:    options.DNSName,
    Content: ip,
    TTL:     120,
    Proxied: false,
  })
}
```

然后，就像网页应用程序一样，我们在Kubernetes中运行这个应用程序作为部署:  

```javascript
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubernetes-cloudflare-sync
  labels:
    app: kubernetes-cloudflare-sync
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kubernetes-cloudflare-sync
  template:
    metadata:
      labels:
        app: kubernetes-cloudflare-sync
    spec:
      serviceAccountName: kubernetes-cloudflare-sync
      containers:
      - name: kubernetes-cloudflare-sync
        image: gcr.io/PROJECT_ID/kubernetes-cloudflare-sync
        args:
        - --dns-name=kubernetes.example.com
        env:
        - name: CF_API_KEY
          valueFrom:
            secretKeyRef:
              name: cloudflare
              key: api-key
        - name: CF_API_EMAIL
          valueFrom:
            secretKeyRef:
              name: cloudflare
              key: email
```


你需要使用cloudflare api密钥和电子邮件地址创建Kubernetes秘密共享:

```javascript
kubectl create secret generic cloudflare --from-literal=email='EMAIL' --from-literal=api-key='API_KEY'
```

 
你还需要创建服务帐户(它允许我们的部署访问Kubernetes APl来检索节点)。首次运行(特别为了GKE):

```javascript
kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user YOUR_EMAIL_ADDRESS_HERE
```

 
然后再应用：

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kubernetes-cloudflare-sync
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubernetes-cloudflare-sync
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-cloudflare-sync-viewer
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubernetes-cloudflare-sync
subjects:
- kind: ServiceAccount
  name: kubernetes-cloudflare-sync
  namespace: default
```

 
RBAC有点程序冗长繁杂，但希望这是有意义的。配置就绪后，运行Cloudflare的应用程序将在任何节点发生更改时进行更新。

结论

Kubernetes将成为管理大型部署的主要方式。尽管在规模上运行Kubernetes面临着重大的技术挑战，而且Kubernetes的许多技术仍处于不断变化之中，但Kubernetes的采用已经达到了临界规模，我们很可能在未来几年看到快速的改进。
我的观点是，Kubernetes对于小型部署也是有意义的，而且目前易于使用且价格低廉。如果你从未尝试过，那么现在就是尝试的最佳时机。
