# 云原生中的Logging和Monitoring模式
Mohamed Ahmed
Dec 23, 2019

# 云原生世界中对可观察性的需求
任何没有公开其运行状况信息，运行于其中的应用程序的状态以及是否出了问题等必要信息的系统，都是毫无用处的。但这已经被反复提及了吧？从大型机和打孔式编程的早期时代开始，就一直在监测温度和功率等等。

这些老旧系统关键在于它们很少更改。如果要进行修改，计划内对其在监控下进行修改，因此这不成问题。此外，该系统作为一个整体运行，由于没有多个活动部件，因此更易于观察。但是，在我们今天生活中的云原生世界，变化是罕见的，这是常态。云原生应用程序遵循的微服务模式使该系统成为高度分布式的系统。因此，数据的测量收集，监控和日志记录需要以不同步的方式进行。让我们简要了解一下云原生环境中的监控所存在的一些挑战：

- 假设您在Kubernetes集群中运行应用程序。Kubernetes使用Pod作为其工作的基础单元。它们用于运行加载应用程序的容器。但是pod本质上是瞬态的。它们被删除，重新创建，重新启动，以及从一个节点移到另一个节点。因此，一旦应用程序行为异常，那么在运行时环境不断变化的情况下，您将在哪里找到线索？
- 由于云原生应用程序天然的的高度分布式特性，跨越十几种服务来满足客户需求，追踪其请求变得越来越困难。如果收到错误的响应或报错消息，您怀疑哪个组件是可能产生错误的原因？

# 云原生中的日志记录
根据经验，应该收集日志并将其存储在托管应用程序的节点之外。其背后的原因是，您需要在单独一个地方查看，分析和关联来自不同来源的不同日志。在高度分布式的环境中，随着服务（和日志）数量的增加，需求变得更加重要。有许多工具可以为您完成这项任务；例如Filebeat，Logstash，Log4j等。应用程序应该在重要事件发生时对其进行日志记录，但它不应决定日志的去向。那是部署来决定的。例如，Python应用程序可能具有以下几行，以提醒新用户已添加到数据库中：

```python
 log.info("{} was added successfully".format(user))
```

当然，应用程序需要知道这一行日志文本应该去哪里。由于我们依赖于相应的环境来了解这个问题的答案，因此我们指示应用程序将其发送到STDOUT和STDERR（如果日志是报错事件）。您应遵循此做法的原因有很多，如下：

- 如果您的环境是短暂的（例如，Kubernetes pods），那么当环境消失（崩溃、删除等）时，容器与其日志紧密耦合会使您无法查看这些日志。如果您的环境是短暂的（例如，Kubernetes pods），且容器与其日志紧密地耦合，当环境消失（崩溃，删除等）时，您将无法查看这些日志。
- 在微服务架构中，用PHP编写后端，使用Python构建中间件以及使用NodeJS构建前端是非常普遍的。这些系统中的每一个都可能使用具有自己的日志记录方式和自己的文件位置的框架。将日志定向到STDOUT和STDERR可以确保我们有一致的收集日志的方式。
- 云原生架构非常灵活，不仅可以为不同的组件使用不同的编程语言，而且还可以使用不同的操作系统。例如，后端可能正在使用仅在Windows计算机上工作的旧系统，而其余基础设施结构在Linux上运行。但是由于STDOUT和STDERR在设计上是任何OS固有特性，这提供了更高的一致性，可以将它们用作统一的日志源。
- STDOUT和STDERR是标准流。因此，它们完全适合日志的性质。日志是数据流；它没有开始或结束，只是在事件发生时才产生文本字符串。因此，从流中启动对日志聚合服务的API调用比使用文件调用更容易。

![Cloud Native Logging & Monitoring 1](https://img-blog.csdnimg.cn/20200417073615405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjk5NjU5NQ==,size_16,color_FFFFFF,t_70#pic_center)
# 测试案例：Kubernetes日志记录
假设您的应用程序托管在Kubernetes集群的三个Pod上。该应用程序配置为每当该应用程序接收并响应Web请求时就打印一行日志。但是，集群的设计使得服务将传入的请求路由到随机的后端Pod。现在，问题是；在查看应用程序日志时，应查询哪个Pod？下图描述了这种情况：
![Cloud Native Logging & Monitoring 2](https://img-blog.csdnimg.cn/20200417074112214.png#pic_center)
由于这种情况很常见，因此Kubernetes提供了一个简单的命令，使您可以查看与特定标签匹配的所有Pod的集群日志：

![bash](https://img-blog.csdnimg.cn/20200417200843981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjk5NjU5NQ==,size_16,color_FFFFFF,t_70#pic_center)
(上图完整命令可以查看原文网址https://www.magalix.com/blog/cloud-native-logging-and-monitoring-pattern)

如预期的那样，该命令返回了详细的输出，因为它是所有标记为app = frontend的Pod的合并日志。我们感兴趣的日志条目是黄色高亮突出显示的条目。要注意的是，日志条目包含容器的IP地址，后跟请求的日期和时间，HTTP谓词以及其他数据。其他两个Pod产生相似的输出，但IP地址不同。在此示例中，我们使用的应用程序是Python Flask。日志消息的格式不是Kubernetes决定的，而是取决于Flask如何记录其事件。在实际的应用程序中，应将应用程序配置为在记录事件时使用容器的主机名。此外，可以在启动容器时设置其主机名。

# 云原生指标
日志和指标之间存在重要区别。日志描述事件的发生。有些事件是绝对重要的（关键的），而其余的事件重要性逐步降低，直到达到debug级别，这是最繁杂的事件了。另一方面，指标描述了应用程序及其基础设施的当前状态。当某些指标达到预定义阈值时，可以设置警报。例如，当CPU超过80%或并发web请求数达到1k（一千）时。

您应该在代码中实现必要的逻辑，以对外公开应用程序的指标。大多数框架已经实现了该功能，但是您可以（并且应该）在需要时根据自己的自定义指标扩展框架的核心功能。

获取指标时，我们基本上有两种方法：基于推的方法和基于拉的方法。让我们来逐个看看：

# 基于拉的方法
在这种方法中，应用程序公开了一个或多个health endpoint。通过HTTP请求访问这些URL将返回该应用程序的运行状况和metric数据。例如，我们的flask API可能有一个health endpoint，该端点公开有关服务当前状态的重要信息。但是，实现此方法会有一些难点：

## 您要从哪个pod中拉取？
在微服务架构中，不止一个组件负责托管应用程序部分，每个服务都具有不止一个Pod以实现高可用性。例如，博客应用程序可能具有身份验证服务，发帖和评论服务。每个服务通常位于负载均衡器之后，以在其副本之间分配负载。您的日志采集控制器访问应用程序的health endpoint，并将返回结果存储在时序数据库中（例如，InfluxDB或Prometheus）。因此，当控制器需要拉取服务以获取metric数据时，它可能会访问负载均衡器的URL，而不是服务本身的。负载均衡器将请求路由到第一个可用的后端Pod，该后端Pod不能涵盖所有Pod的运行状况。下图说明了这种情况：

![Cloud Native Logging & Monitoring 3](https://img-blog.csdnimg.cn/2020041707421549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjk5NjU5NQ==,size_16,color_FFFFFF,t_70#pic_center)

此外，由于响应健康检查请求的可能是不同的pod，因此我们需要一种机制，每个Pod可以通过该机制在响应中标识自己（主机名，IP地址等）。

解决此问题的一种可能的解决方案是使监视系统负责检测应用程序中不同服务的URL，而不是依赖于将服务识别移至客户端的负载平衡器。这样的话，控制器定期执行两项任务：

 1. 发现可用的服务。在Kubernetes中执行此操作的一种方法是将pod放置在headless service后面，该服务返回单个Pod的URL。
 2. 通过点击每个发现的pod的相应URL，获取pod的health metric。

下图描述了这种方法：

![Cloud Native Logging & Monitoring 4](https://img-blog.csdnimg.cn/20200417074717126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjk5NjU5NQ==,size_16,color_FFFFFF,t_70#pic_center)

使用这种方法，监视系统必须有权访问pods的内部IP地址。因此，必须将其部署为集群的一部分。常见的解决方案如Prometheus operators不仅与集群内部运行的Pod深度集成，而且还与集群本身的系统级metrics深度集成。

# 基于推的方法
在这种方法中，应用程序负责查找metrics服务器的位置并将数据推送到该地址。最初，这种方法似乎给应用程序增加了额外的复杂性。开发人员必须构建用于metric采集和推送的必要模块。但是，通过使用sidecar模式可以完全避免这种情况。

sidecar模式利用了一个事实，即一个Pod可以托管多个容器，所有这些容器共享相同的网络地址和卷。他们可以通过环回地址localhost相互通信。因此，我们可以放置一个仅负责日志和(或)指标采集并将其推送到metric服务器或日志聚合器的容器。

使用这种模式，您不需要对应用程序进行更改，因为sidecar容器已经通过health endpoints收集了必要的指标，并将其发送到服务器。如果服务器的IP地址或类型发生更改，我们只需要更改sidecar容器的实现即可。该应用程序保持不变。下图演示了如何使用sidecar容器（也称为Ambassador或Envoy）来收集和推送metrics：

![Cloud Native Logging & Monitoring 5](https://img-blog.csdnimg.cn/20200417074815226.png#pic_center)

值得一提的是，这种模式可以在应用程序基础上公开更多metric。这是可能的，因为sidecar容器本身可以公开有关应用程序性能的其他数据；例如，响应延迟，失败请求的数量等等。

# TL; DR
- 在出现问题以前就去了解你的程序的运作，这并不是一个新的概念。从非常古老的计算时代开始就遵循这种做法。
- 即使在非云原生环境中，指标也必须存储在生成该指标的节点之外，以获得更好的可见性，关联性和聚合性。
- 在微服务架构中，由于有许多metrics来源，因此在日志收集方面存在许多挑战。
- 像Kubernetes这样的编排系统具有它们自己处理多个数据源的方式。例如，使用-l参数，您可以收集在同一标签下不同容器的所有输出。
- 将日志广播到标准输出和标准错误通道比将日志写入本地文件更加有效。之后，日志采集代理可以在多个操作系统/应用程序之间更轻松，更统一地处理STDOUT和STDERR。
- 对于metrics采集，我们基本上有两种在云原生环境中进行采集的方法：基于拉的方式和基于推的方式。
- 基于拉的方法依赖于metric控制器来发现适当的服务并与之通信。为此，它访问指定的health endpoint来获取metrics。
- 基于推的方法依赖于服务来确定metric服务器的端点。为了避免增加应用程序的开销，我们使用sidecar容器代替应用程序收集指标并将指标发送到服务器。