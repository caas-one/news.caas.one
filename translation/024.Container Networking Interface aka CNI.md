# 集装箱联网接口（CNI）
CNI经常和Kubernetes被同时提起。它现在已经成为Kubernetes的一个组成部分，静静地做着跨不同节点连接吊舱的工作，并且能够很好地适应不同类型的网络解决方案（覆盖、纯L3等）。尽管如此，它不仅仅存在于Kubernetes中。它本身是一个独立的框架，有自己的规范，不仅可以与kubernetes一起使用，还可以与其他容器编排工具（如Mesos、Openshift等）一起使用。

CNI是什么？ 简而言之，它是网络命名空间和网络插件之间的接口。 容器运行时（例如Docker或Rocket）是网络命名空间。 Network Plugin是遵循CNI规范的实现，该插件用于实现获取容器运行时的状态，并将其配置（附加，分离）到网络。

这个插件作为可执行文件存在。 调用时，它会读入JSON配置以获取所有必需参数，以便使用网络配置容器。该插件还可以调用其他插件来执行必要的任务，例如将IP分配给容器，这意味着CNI将IPAM与核心网络插件分开并保持正交，因此存在CNI-IPAM插件。例如，大多数情况下，在附加期间，JSON配置将包含“net”插件的条目，该插件完成创建接口的工作，以便容器运行时连接到网络；以及“ipam”条目，以便告诉“net”插件用于IP分配的IPAM插件。

## CNI规范:
以下是通用参数：
![通用参数1](https://img-blog.csdnimg.cn/20190804230707273.png)![通用参数2](https://img-blog.csdnimg.cn/20190804230739661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1doaXNwZXJfV2FuZw==,size_16,color_FFFFFF,t_70)
除了这些参数之外，配置还可以包含特定于所使用插件的字段。![特定字段](https://img-blog.csdnimg.cn/20190804231115617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1doaXNwZXJfV2FuZw==,size_16,color_FFFFFF,t_70)
>旁注：也可以为一个容器调用多个CNI插件，在这种情况下，需要在JSON配置中传递一组插件。在这种情况下，JSON规范需要一个名为“插件”的字段，以及插件的相应顺序。

除了NET和IPAM插件之外，还有另一个称为“meta”插件的类。这些插件可以是核心网络和IPAM插件的包装器。一个meta插件通常会将它的CNI配置转换为core net（核心网）和ipam配置（例如用于覆盖网络的flannel），或者对核心插件的输出进行某种额外的配置（例如端口映射、调优接口、sysctl等）。

让我们进入设置。

所以，我有一台运行Ubuntu 16.04的移动机器，已经从 github.com/containernetworking/cni 构建了 *cnitool* 可执行文件，从 github.com/containernetworking/plugins 构建了插件的可执行文件。让我们在 *$home*   中创建一个名为 *cni* 的目录，并将 *cnitool* 复制到其中。现在让我们把所有的插件可执行文件放在 *cni* 目录中的 *plugins* 目录中。另外，对于CNI配置，我们将在 *cni* 目录中创建一个名为 *net.d* 的目录。现在，它是空的。

```
vagrant@machine-01:~/cni$ tree 
. 
├── cnitool 
├── net.d 
└── plugins
    ├── bandwidth
    ├── bridge
    ├── dhcp    
    ├── flannel    
    ├── host-device    
    ├── host-local    
    ├── ipvlan    
    ├── loopback    
    ├── macvlan    
    ├── portmap    
    ├── ptp    
    ├── sample    
    ├── static    
    ├── tuning    
    └── vlan
```
现在，让我们来看看一个基本的CNI——“桥”插件。桥插件将创建..好吧，一个网桥（如果不存在）并通过veth对，将容器运行时连接到它。就像众所周知的docker0接口一样。

假设我们已经启动了两个具有 *--net=none* （不连接到任何网络）的Docker容器，让我们来看一个CNI config示例来将它们添加到网桥网络。
![30-mybridge.conf](https://img-blog.csdnimg.cn/20190804235328429.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1doaXNwZXJfV2FuZw==,size_16,color_FFFFFF,t_70)
这里的大多数项目都是不言而喻的。按照规定，网桥将充当容器的默认网关。这里使用的IPAM插件是 *host-local* ，这是一个非常简单的IPAM，它从给定的范围分配IP地址（请参见“IPAM”部分中的“子网”字段）。让我们将这个JSON复制到 *net.d* 目录中。

现在，让我们 *cd* 到 *cni* 目录中，并查看我们将用于将容器添加到网络中的 *cnitool* 。

```
vagrant@machine-01:~/cni$ ./cnitool -h
cnitool: Add or remove network interfaces from a network namespace
  cnitool add <net> <netns>
  cnitool del <net> <netns>
```
它采用网络的名称（在 *net.d* 目录中的CNI配置文件中提到）和容器的网络名称空间的路径。

我们现在运行 *cnitool* 来添加容器。
```
vagrant@machine-01:~/cni$ sudo CNI_PATH=/home/vagrant/cni/plugins \ 
NETCONFPATH=/home/vagrant/cni/net.d \ 
./cnitool add dbnet                 \ 
$(docker inspect mycnitest1 |       \ 
jq .[0].NetworkSettings.SandboxKey | tr -d '"')
```

*cnitool* 将扫描 *net.d* 目录，选择网络名为“dbnet”的配置文件，然后将容器“mycnitest1”添加到网络中。我们也将对另一个容器重复同样的过程。

所以现在我们有两个容器连接到桥上。容器和虚拟机之间应该可以相互ping通，包括主机或google.com之类的外部网络。（ipMasq = true）。为了从网络中删除一个容器，我们将基本上运行相同的命令，但有一个非常小但非常重要的区别。（注意“添加”至“删除”）

```
vagrant@machine-01:~/cni$ sudo CNI_PATH=/home/vagrant/cni/plugins \
NETCONFPATH=/home/vagrant/cni/net.d \
./cnitool del dbnet                 \
$(docker inspect mycnitest1 |       \
jq .[0].NetworkSettings.SandboxKey | tr -d '"')
```
我们可以在容器上调用更多的CNI插件进行额外配置。例如，我们可以使用 *portmap* 插件将容器端口映射到主机。下面是一个带链接的CNI配置示例（一个接一个运行CNI插件）。注意新字段“plugins”和“portMappings=true”
![30-mybridge-portmap.conist](https://img-blog.csdnimg.cn/20190805143012340.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1doaXNwZXJfV2FuZw==,size_16,color_FFFFFF,t_70)
端口映射可以通过名为 *CAP_ARGS* 的环境变量，作为其运行时配置的一部分提供给 *portmap* 。 让我们在网络中添加一个容器，使用此CNI配置和通过环境变量 *CAP_ARGS* 设置的运行时参数。
```
vagrant@machine-01:~/cni$ sudo CNI_PATH=/home/vagrant/cni/plugins \ 
NETCONFPATH=/home/vagrant/cni/net.d                         \ 
CAP_ARGS='{"portMappings":
[{"hostPort":6000,"containerPort":3000,"protocol":"tcp"}]}' \
./cnitool add dbnet                                         \ 
$(docker inspect mycnitest1 |                               \
jq .[0].NetworkSettings.SandboxKey | tr -d '"')
```
现在，我们应该能够连接到3000端口上,并实现容器内部运行的进程，方法是连接到虚拟机（machine-01）上的6000端口。

关于如何实现这一点，我们可以看一下在调用这些插件时配置的iptables（NAT：*iptables -L -t nat* ）规则。

差不多了！这是对CNI的简短介绍，其中有一个非常基本的示例，只有一个VM（节点）。这应该能为探索桥、portmap插件旁边的其他核心网络插件提供一个良好的基础。

当我们需要容器在节点之间进行通信时，事情就变得非常有趣，允许非常有趣的网络拓扑（覆盖，纯L3路由）。这就是flannel、calico、weave等元插件发挥作用的地方。希望能在另一个帖子中介绍这些内容。
