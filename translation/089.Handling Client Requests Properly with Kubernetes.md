# 使用Kubernetes正确处理客户请求

作者：Marko Lukša 原文链接：[Handling Client Requests Properly with Kubernetes](https://freecontent.manning.com/handling-client-requests-properly-with-kubernetes/?utm_sq=g6rhsr1fby)

不用说，我们希望客户端请求得到正确处理。并且显然不希望在pod启动或关闭时出现断开连接的情况。Kubernetes自己并不能保证这种情况永远不会发生。因此，你的应用程序需要遵循一些规则来防止断开连接。本文将讨论这些规则。

想在Kubernetes上节省37%的费用，只需在manning.com的收银台输入fccluksa代码到折扣码框。

## 确保所有的客户端请求都被正确处理

让我们从pod的客户端(使用pod提供的服务的客户端)的角度来看看pod服务的生命周期。我们想要确保客户的请求得到了正确的处理，因为如果在pods启动或关闭时连接开始中断，我们就有麻烦了。Kubernetes本身并不能保证这不会发生，所以让我们看看我们需要做些什么来阻止它发生。

## 在pod启动时防止断开客户机连接

如果你了解服务和服务端点的工作方式，确保在pod启动时正确处理每个连接是相当简单的。启动pod时，它被添加为所有服务的端点，其标签选择器与pod的标签相匹配。pod还需要向Kubernetes发出准备就绪的信号。直到它不会成为服务端点，因此不会从客户端接收任何请求。

如果你没有在你的pod规格中指定一个就绪探测器，pod会一直被认为是准备就绪的。这意味着它将几乎立即开始接收请求——只要第一个kube代理更新其节点上的iptables规则，第一个客户机pod就会尝试连接到服务。如果你的应用还没有准备好被连接，客户端会收到“连接被拒绝”类型的错误。

你所需要做的就是确保就绪探测仅在应用程序准备好正确处理传入请求时才返回成功。第一步最好是添加一个HTTPGFT准备就绪探测，并将其指向应用程序的基本URL。在很多情况下，这足以让你在应用程序中实现一个特殊的准备就绪端点。

## 防止在pod关闭期间断开连接

现在让我们看看在pod使用期限的另一端会发生什么——当pod被删除和它的集装箱终止时。pod的集装箱应该在收到SIGTERM信号时(甚至在此之前——在执行预停止勾连点时)就开始彻底地关闭，但是这能确保所有客户机请求都得到正确处理吗?

当应用程序收到终止信号时应该如何表现?它应该继续接受请求吗?已经收到但尚未完成审核的请求怎么办?持久HTTP连接呢?它可能位于请求之间，但处于打开状态(连接上没有活动请求)?在回答这些问题之前，我们需要详细了解删除pod时集群中发生的一系列事件。

## 理解pod删除时发生的事件顺序

你需要始终记住，Kubernetes集群中的组件在多台机器上会作为单独的进程运行。它们不是一个单一的大的整体过程的一部分。所有组件在同一页面上显示集群的状态都需要一定的时间。让我们通过查看删除pod时集群中发生的情况来研究这一事实。

当APl服务器收到删除pod的请求时，它首先在主节点中修改状态，然后通知监视者删除。这些观察者包括Kubelet和端点控制器。这两个事件序列是并行发生的(用A或B标记)，如图1所示。

![](https://freecontent.manning.com/wp-content/uploads/Luksa_HCRPwK_01.png)

*图1删除pod时发生的事件序列*

在一系列事件,你会发现一旦Kubelet接收通知,pod运行就应该终止,它启动关闭序列(运行预停止勾连点,发送SIGTERM,等待一段时间,然后强行结束集装箱运行，如果它尚未终止自己的运行)。如果应用程序响应SIGTERM bv立即停止接收客户端请求，任何试图连接到它的客户端都会收到一个连接拒绝的信号。由于APl服务器到Kubelet的直接路径，从删除pod到发生这种情况所需的时间相对较短。

现在，让我们看看在另一个事件序列中发生了什么—从iptables规则中删除pod之前的事件(图中的序列B)。当端点控制器(在Kubernetes控制平面的控制器管理器中运行)接收到pod被删除的通知时，它将pod作为该pod所属的所有服务中的端点删除。它通过向API服务器发送REST请求来修改端点API目的来实现这一点。然后APl服务器通知所有监视端点对象的人。在这些监视者中有运行在工作节点上的kube代理。每一个代理在其节点更新intablesrules是为了防止新的连接被forwardec终止到pod,一个重要细节是消除iptables规则对现有客户的联系，而不影响那些已经连接到pod,并且能够通过这些现有的连接发送额外的请求到pod。

这两个事件序列是并行发生的。最有可能。在pod中关闭应用程序进程所需的时间比更新iptables规则所需的时间稍短。这是因为导致更新iptables规则的事件链要长得多(参见图2)。因为事件必须首先到达端点控制器，并且向APl服务器发送一个新请求，然后API服务器必须在代理服务器最终修改iptables规则之前通知Kube代理服务器。这意味着在所有节点上更新iptables规则之前，SIGTERM信号很有可能就已经发送了。

![](https://freecontent.manning.com/wp-content/uploads/Luksa_HCRPwK_02.png)

*图2删除pod时的事件时间线*

结果是pod可能仍然接收客户端请求后收到终止信号,低频应用立即停止接受连接,它会导致客户收到“拒绝连接”类型的错误(比如pod启动时发生了什么如果你的应用程序不能够立即接受连接,你就不会为它定义一个准备就绪的探测)。

## 解决这个问题

谷歌一下这个问题的解决方案，你会发现在你的pod上添加一个就绪探测器似乎可以解决这个问题。假设，所有你需要做的是使准备探测器开始时一旦pod接受到信号它就会失败。这将导致pod作为服务的端点被删除。只有在准备就绪探测连续失败几次之后才会进行删除(这可以在准备就绪探测规范中配置)。显然，在从iptables规则中删除pod之前，删除操作仍然需要到达Kube代理器。

而现实中，准备就绪探测与整个过程完全无关。端点控制器一收到删除pod的通知(当pod规范中的删除Timestampfield不再为空时)，就从服务端点删除pod。从那时起，准备就绪探测器就无关紧要了。

这个问题的正确解决办法是什么?我们如何确保所有的请求都得到充分处理?

很明显，pod需要继续接受连接，即使它收到了终止信号。直到所有的kube代理都完成了对iptables规则的更新。而且，不仅仅是kube代理，也可能有进入控制器或负载平衡器，并且不通过服务(iptables)转发直接连接到pod，这也包括使用客户端负载平衡的客户端，为了确保没有客户端连接中断，你必须等待，直到所有客户端显示它们不再将连接转发到pod。

这是不可能的，因为所有这些组件都分布在许多不同的计算机上。即使你知道它们每一个的位置，并且可以等到它们都准备好了之后再关闭pod，如果其中一个组件没有反应，你会怎么做?你要等多久才能得到回应?记住，在这段时间里，你将会延迟关机的进程。

唯一合理的方法是等待足够长的时间，以确保所有代理器都完成了它们的工作。但是多久才算够长呢?在大多数情况下几秒钟就足够了，但显然，不能保证每次都足够。当APl服务器或端点控制器过载时，通知到达Kube代理器可能需要更长的时间。很重要的一点是，你不可能完美地解决所有问题，但是即使是5秒或10秒的延迟也会极大地改善用户体验。你可以使用更长的延迟，但不要太过了，因为延迟会阻止集装箱立即关闭，并导致删除pod之后很长时间仍然显示在列表中，这对于正在删除pod的用户来说是极大的挫败。

正确关闭应用程序包括以下步骤:

等待几秒钟，然后停止接受新连接，

关闭所有不在请求中间但保持的连接。

等待所有活动请求完成，然后

完全关闭

要了解此过程中连接和请求的情况，请仔细查看图3。

![](https://freecontent.manning.com/wp-content/uploads/Luksa_HCRPwK_02.png)

*图3接收终止信号后正确处理现有连接和新连接*

不像接收到终止信号后立即退出过程那么简单，对吗?这一切经历值得吗?那得由你来决定。但是，你至少可以添加一个等待几秒钟的预停止勾连点。大概是这样的:

```yaml
lifecycle:                   
  preStop:                   
    exec:                    
      command:               
      - sh
      - -c
      - "sleep 5"
```


这样，你根本不需要修改应用程序的代码。如果你的应用程序已经确保所有的飞行请求被完全处理，这个预停止延迟可能是你所需要的。

这就是本文的全部内容。

想了解更多，可以在liveBook上查看整本书。